train:
  weights: 'yolov5s.pt'  # initial weights path
  cfg: ''  # model.yaml path
  data: 'data/coco128.yaml'  # data.yaml path
  hyp: 'data/hyp.scratch.yaml'  # hyperparameters path
  epochs: 300
  batch_size: 16  # total batch size for all GPUs
  img_size: [640, 640]  # [train, test] image sizes
  rect: false  # rectangular training
  resume: false  # resume most recent training
  nosave: false  # only save final checkpoint
  notest: false  # only test final epoch
  noautoanchor: false  # disable autoanchor check
  evolve: false  # evolve hyperparameters
  bucket: ''  # gsutil bucket
  cache_images: false  # cache images for faster training
  image_weights: false  # use weighted image selection for training
  device: ''  # cuda device, i.e. 0 or 0,1,2,3 or cpu
  multi_scale: false  # vary img-size +/- 50%%
  single_cls: false  # train multi-class data as single-class
  adam: false  # use torch.optim.Adam() optimizer
  sync_bn: false  # use SyncBatchNorm, only available in DDP mode
  local_rank: -1  # DDP parameter, do not modify
  workers: 8  # maximum number of dataloader workers
  project: 'runs/train'  # save to project/name
  entity:  # W&B entity
  name: 'exp'  # save to project/name
  exist_ok: false  # existing project/name ok, do not increment
  quad: false  # quad dataloader
  linear_lr: false  # linear LR
  label_smoothing: 0.0  # Label smoothing epsilon
  upload_dataset: false  # Upload dataset as W&B artifact table
  bbox_interval: -1  # Set bounding-box image logging interval for W&B
  save_period: -1  # Log model after every "save_period" epoch
  artifact_alias: latest  # version of dataset artifact to be used
test:
  weights: 'runs/train/weights/best.pt'  # model.pt path(s)
  data: 'data/coco128.yaml'  # *.data path
  batch_size: 32  # size of each image batch
  img_size: 640  # inference size (pixels)
  conf_thres: 0.001  # object confidence threshold
  iou_thres: 0.6  # IOU threshold for NMS
  task: 'val'  # train, val, test, speed or study
  device: ''  # cuda device, i.e. 0 or 0,1,2,3 or cpu
  single_cls: false  # treat as single-class dataset
  augment: false  # augmented inference
  verbose: false  # report mAP by class
  save_txt: false  # save results to *.txt
  save_hybrid: false  # save label+prediction hybrid results to *.txt
  save_conf: false  # save confidences in --save-txt labels
  save_json: false  # save a cocoapi-compatible JSON results file
  project: 'runs/test'  # save to project/name
  exist_ok: false  # existing project/name ok, do not increment
detect:
  weights: 'runs/train/weights/best.pt'  # model.pt path(s)
  source: 'data/images'  # source: file/folder, 0 for webcam
  img_size: 640  # inference size (pixels)
  conf_thres: 0.25  # object confidence threshold
  iou_thres: 0.45  # IOU threshold for NMS
  max_det: 1000  # maximum number of detections per image
  device: ''  # cuda device, i.e. 0 or 0,1,2,3 or cpu
  view_img: false  # display results
  save_txt: false  # save results to *.txt
  save_conf: false  # save confidences in --save-txt labels
  save_crop: false  # save cropped prediction boxes
  nosave: false  # do not save images/videos
  classes: []  # filter by class: --class 0, or --class 0 2 3
  agnostic_nms: false  # class-agnostic NMS
  augment: false  # augmented inference
  update: false  # update all models
  project: 'runs/detect'  # save results to project/name
  exist_ok: false  # existing project/name ok, do not increment
  line_thickness: 3  # bounding box thickness (pixels)
  hide_labels: false  # hide labels
  hide_conf: false  # hide confidences
# DISCUSS: we could remove this stage and version this as CI artifacts
export:
  weights: runs/train/weights/best.pt
